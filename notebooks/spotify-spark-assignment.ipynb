{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7ded06-271b-4228-8d10-d76db0d0aa05",
   "metadata": {},
   "source": [
    "# Análisis de Datos con Spark: Explorando el Universo Musical de Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0da56e1-21f5-4b3b-b67e-d5018569fc0a",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2107b5-60d6-409b-9c20-f94c6863f711",
   "metadata": {},
   "source": [
    "En esta tarea, exploraremos un extenso conjunto de datos de canciones de Spotify. Este dataset contiene características de audio detalladas para cientos de miles de canciones, junto con metadatos como artista, año de lanzamiento, popularidad y géneros musicales. A través del análisis de estos datos, podremos descubrir patrones en la evolución de la música a lo largo del tiempo, entender qué hace que algunas canciones sean más populares que otras, y crear sistemas de recomendación basados en características de audio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b28b95-2250-4b11-9f6e-4114835a88f2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afffab09-36ff-41b6-9bc1-cc205be92081",
   "metadata": {},
   "source": [
    "## Nombre del Dataset: Spotify Song Attributes Dataset Fuente: \n",
    "Kaggle - Spotify Dataset 1921-2020, 600k+ Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d24d75-10d4-42c2-9ba8-f800b6289e37",
   "metadata": {},
   "source": [
    "Este dataset incluye:\n",
    "\n",
    "tracks.csv: Contiene información sobre más de 600,000 canciones, con características como:\n",
    "\n",
    "track_id: Identificador único de la canción\n",
    "name: Nombre de la canción\n",
    "popularity: Puntuación de popularidad (0-100)\n",
    "duration_ms: Duración en milisegundos\n",
    "explicit: Si la canción tiene contenido explícito\n",
    "artists: Artistas que participaron en la canción\n",
    "id_artists: IDs de los artistas\n",
    "release_date: Fecha de lanzamiento\n",
    "danceability: Qué tan adecuada es la canción para bailar (0.0-1.0)\n",
    "energy: Medida de intensidad y actividad (0.0-1.0)\n",
    "key: Tonalidad de la canción (0-11)\n",
    "loudness: Volumen general en decibelios (dB)\n",
    "mode: Modalidad de la canción (mayor o menor)\n",
    "speechiness: Presencia de palabras habladas (0.0-1.0)\n",
    "acousticness: Medida de si la canción es acústica (0.0-1.0)\n",
    "instrumentalness: Predice si una canción no contiene vocales (0.0-1.0)\n",
    "liveness: Detecta presencia de audiencia (0.0-1.0)\n",
    "valence: Positividad musical de la canción (0.0-1.0)\n",
    "tempo: Velocidad o ritmo estimado en BPM\n",
    "time_signature: Compás estimado\n",
    "artists.csv: Información sobre los artistas, incluyendo:\n",
    "\n",
    "id: ID único del artista\n",
    "followers: Número de seguidores\n",
    "genres: Géneros asociados con el artista\n",
    "name: Nombre del artista\n",
    "popularity: Puntuación de popularidad (0-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fed307-c0bb-4507-9021-ea5cded7bb15",
   "metadata": {},
   "source": [
    "# Parte 1: Configuración del Entorno y Carga de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9597aaa-202a-40e8-a9dc-e8d9249dd6d2",
   "metadata": {},
   "source": [
    "## Paso 1: Configurar Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6ce0ad-3ee2-4775-b925-f4ae63bd65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesión de Spark Creada con éxito!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Crear la sesión de Spark con configuración local optimizada\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SpotifySparkAssignment\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Ajustar configuraciones adicionales para entorno local\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "print(\"Sesión de Spark Creada con éxito!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96bb5fd-9ad5-4142-93c5-75412b3d41ed",
   "metadata": {},
   "source": [
    "## Paso 2: Cargar los archivos CSV de tracks y artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2237d6-c997-4fba-bc1b-6dbc8c6024da",
   "metadata": {},
   "source": [
    "## Cargamos los datasets tracks.csv y artists.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd20b263-abd6-4ced-ab1f-fa7e0848e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cargada Exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta base de los datos\n",
    "data_path = \"/home/jovyan/work/data/spotify/\"\n",
    "\n",
    "# Cargar tracks.csv en un DataFrame de Spark\n",
    "tracks_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(data_path + \"tracks.csv\")\n",
    "\n",
    "# Cargar artists.csv en un DataFrame de Spark\n",
    "artists_df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(data_path + \"artists.csv\")\n",
    "\n",
    "print(\"Data Cargada Exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4201866-4211-496f-978b-463fb9a695aa",
   "metadata": {},
   "source": [
    "# Paso 3: Revisar el esquema y mostrar primeras filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3ff794-cb98-4258-b3fd-9fa870c3391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema de tracks_df:\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- duration_ms: string (nullable = true)\n",
      " |-- explicit: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- id_artists: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- valence: string (nullable = true)\n",
      " |-- tempo: string (nullable = true)\n",
      " |-- time_signature: string (nullable = true)\n",
      "\n",
      "\n",
      "Esquema de artists_df:\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- followers: double (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      "\n",
      "\n",
      "Primeras 5 filas de tracks_df:\n",
      "+----------------------+-----------------------------------+----------+-----------+--------+-------------------+--------------------------+------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+\n",
      "|id                    |name                               |popularity|duration_ms|explicit|artists            |id_artists                |release_date|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo  |time_signature|\n",
      "+----------------------+-----------------------------------+----------+-----------+--------+-------------------+--------------------------+------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+\n",
      "|35iwgR4jXetI318WEWsa1Q|Carve                              |6         |126903     |0       |['Uli']            |['45tIt06XoI0Iio4LBEVpls']|1922-02-22  |0.645       |0.445 |0  |-13.338 |1   |0.451      |0.674       |0.744           |0.151   |0.127  |104.851|3             |\n",
      "|021ht4sdgPcrDgSk7JTbKY|Capítulo 2.16 - Banquero Anarquista|0         |98200      |0       |['Fernando Pessoa']|['14jtPCOoNZwquk5wd9DxrY']|1922-06-01  |0.695       |0.263 |0  |-22.136 |1   |0.957      |0.797       |0.0             |0.148   |0.655  |102.009|1             |\n",
      "|07A5yehtSnoedViJAZkNnc|Vivo para Quererte - Remasterizado |0         |181640     |0       |['Ignacio Corsini']|['5LiOoJbxVSAMkBS2fUm3X2']|1922-03-21  |0.434       |0.177 |1  |-21.18  |1   |0.0512     |0.994       |0.0218          |0.212   |0.457  |130.418|5             |\n",
      "|08FmqUhxtyLTn6pAh6bk45|El Prisionero - Remasterizado      |0         |176907     |0       |['Ignacio Corsini']|['5LiOoJbxVSAMkBS2fUm3X2']|1922-03-21  |0.321       |0.0946|7  |-27.961 |1   |0.0504     |0.995       |0.918           |0.104   |0.397  |169.98 |3             |\n",
      "|08y9GfoqCWfOGsKdwojr5e|Lady of the Evening                |0         |163080     |0       |['Dick Haymes']    |['3BiJGZsyX9sJchTqcSA7Su']|1922        |0.402       |0.158 |3  |-16.9   |0   |0.039      |0.989       |0.13            |0.311   |0.196  |103.22 |4             |\n",
      "+----------------------+-----------------------------------+----------+-----------+--------+-------------------+--------------------------+------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Primeras 5 filas de artists_df:\n",
      "+----------------------+---------+------+----------------------------------------------+----------+\n",
      "|id                    |followers|genres|name                                          |popularity|\n",
      "+----------------------+---------+------+----------------------------------------------+----------+\n",
      "|0DheY5irMjBUeLybbCUEZ2|0.0      |[]    |Armid & Amir Zare Pashai feat. Sara Rouzbehani|0         |\n",
      "|0DlhY15l3wsrnlfGio2bjU|5.0      |[]    |ปูนา ภาวิณี                                   |0         |\n",
      "|0DmRESX2JknGPQyO15yxg7|0.0      |[]    |Sadaa                                         |0         |\n",
      "|0DmhnbHjm1qw6NCYPeZNgJ|0.0      |[]    |Tra'gruda                                     |0         |\n",
      "|0Dn11fWM7vHQ3rinvWEl4E|2.0      |[]    |Ioannis Panoutsopoulos                        |0         |\n",
      "+----------------------+---------+------+----------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Total de canciones (tracks_df): 586672\n",
      "Total de artistas (artists_df): 1162095\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el esquema (columnas y tipos) de tracks_df y artists_df\n",
    "print(\"Esquema de tracks_df:\")\n",
    "tracks_df.printSchema()\n",
    "print(\"\\nEsquema de artists_df:\")\n",
    "artists_df.printSchema()\n",
    "\n",
    "# Mostrar las primeras 5 filas de cada DataFrame\n",
    "print(\"\\nPrimeras 5 filas de tracks_df:\")\n",
    "tracks_df.show(5, truncate=False)\n",
    "print(\"\\nPrimeras 5 filas de artists_df:\")\n",
    "artists_df.show(5, truncate=False)\n",
    "\n",
    "# (Opcional) Contar registros en cada DataFrame\n",
    "track_count = tracks_df.count()\n",
    "artist_count = artists_df.count()\n",
    "print(f\"\\nTotal de canciones (tracks_df): {track_count}\")\n",
    "print(f\"Total de artistas (artists_df): {artist_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46569446-9f3f-4fad-8439-9a0d42cf09e6",
   "metadata": {},
   "source": [
    "# Paso 4: Limpieza y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb79990-2900-4e2d-9d49-7a6bd442a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema de tracks_clean:\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- duration_ms: string (nullable = true)\n",
      " |-- explicit: string (nullable = true)\n",
      " |-- artists: string (nullable = true)\n",
      " |-- id_artists: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- valence: string (nullable = true)\n",
      " |-- tempo: string (nullable = true)\n",
      " |-- time_signature: string (nullable = true)\n",
      " |-- release_date: date (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- duration_min: double (nullable = true)\n",
      "\n",
      "Primeras 5 filas de tracks_clean:\n",
      "+----------------------+-----------------------------------+----------+-----------+--------+-------------------+--------------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+------------+------------+------------+\n",
      "|id                    |name                               |popularity|duration_ms|explicit|artists            |id_artists                |danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo  |time_signature|release_date|release_year|duration_min|\n",
      "+----------------------+-----------------------------------+----------+-----------+--------+-------------------+--------------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+------------+------------+------------+\n",
      "|35iwgR4jXetI318WEWsa1Q|Carve                              |6         |126903     |0       |['Uli']            |['45tIt06XoI0Iio4LBEVpls']|0.645       |0.445 |0  |-13.338 |1   |0.451      |0.674       |0.744           |0.151   |0.127  |104.851|3             |1922-02-22  |1922        |2.12        |\n",
      "|021ht4sdgPcrDgSk7JTbKY|Capítulo 2.16 - Banquero Anarquista|0         |98200      |0       |['Fernando Pessoa']|['14jtPCOoNZwquk5wd9DxrY']|0.695       |0.263 |0  |-22.136 |1   |0.957      |0.797       |0.0             |0.148   |0.655  |102.009|1             |1922-06-01  |1922        |1.64        |\n",
      "|07A5yehtSnoedViJAZkNnc|Vivo para Quererte - Remasterizado |0         |181640     |0       |['Ignacio Corsini']|['5LiOoJbxVSAMkBS2fUm3X2']|0.434       |0.177 |1  |-21.18  |1   |0.0512     |0.994       |0.0218          |0.212   |0.457  |130.418|5             |1922-03-21  |1922        |3.03        |\n",
      "|08FmqUhxtyLTn6pAh6bk45|El Prisionero - Remasterizado      |0         |176907     |0       |['Ignacio Corsini']|['5LiOoJbxVSAMkBS2fUm3X2']|0.321       |0.0946|7  |-27.961 |1   |0.0504     |0.995       |0.918           |0.104   |0.397  |169.98 |3             |1922-03-21  |1922        |2.95        |\n",
      "|08y9GfoqCWfOGsKdwojr5e|Lady of the Evening                |0         |163080     |0       |['Dick Haymes']    |['3BiJGZsyX9sJchTqcSA7Su']|0.402       |0.158 |3  |-16.9   |0   |0.039      |0.989       |0.13            |0.311   |0.196  |103.22 |4             |1922-01-01  |1922        |2.72        |\n",
      "+----------------------+-----------------------------------+----------+-----------+--------+-------------------+--------------------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas que tengan NULL en release_date o duration_ms\n",
    "tracks_df = tracks_df.dropna(subset=[\"release_date\", \"duration_ms\"])\n",
    "\n",
    "# Si release_date tiene solo 4 caracteres (AAAA), añadir \"-01-01\" para formar una fecha completa\n",
    "tracks_df = tracks_df.withColumn(\n",
    "    \"release_date_fixed\",\n",
    "    F.when(F.length(\"release_date\") == 4, F.concat(F.col(\"release_date\"), F.lit(\"-01-01\")))\n",
    "     .otherwise(F.col(\"release_date\"))\n",
    ")\n",
    "\n",
    "# Convertir release_date_fixed a tipo fecha y extraer el año\n",
    "tracks_df = tracks_df.withColumn(\"release_date_fixed\", F.to_date(\"release_date_fixed\", \"yyyy-MM-dd\"))\n",
    "tracks_df = tracks_df.withColumn(\"release_year\", F.year(\"release_date_fixed\"))\n",
    "\n",
    "# Crear columna duration_min convirtiendo milisegundos a minutos (redondeado a 2 decimales)\n",
    "tracks_df = tracks_df.withColumn(\"duration_min\", F.round(F.col(\"duration_ms\") / 60000.0, 2))\n",
    "\n",
    "# Filtrar por año de lanzamiento razonable y duración positiva\n",
    "tracks_df = tracks_df.filter(\n",
    "    (F.col(\"release_year\").between(1920, 2025)) & \n",
    "    (F.col(\"duration_ms\") > 0)\n",
    ")\n",
    "\n",
    "# Crear el DataFrame final de tracks limpios\n",
    "tracks_clean = tracks_df.drop(\"release_date\") \\\n",
    "    .withColumnRenamed(\"release_date_fixed\", \"release_date\")\n",
    "\n",
    "# Revisar el esquema y algunas filas del DataFrame limpio\n",
    "print(\"Esquema de tracks_clean:\")\n",
    "tracks_clean.printSchema()\n",
    "print(\"Primeras 5 filas de tracks_clean:\")\n",
    "tracks_clean.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876db80e-5167-4602-b572-39bf51e3d75f",
   "metadata": {},
   "source": [
    "# Paso 5: Guardar los datos limpios en formato Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85198cef-cee1-47ee-927c-553208011647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Parquet guardado en /home/jovyan/work/data/spotify/tracks_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# Guardar tracks_clean como archivo Parquet (se creará un directorio de Parquet)\n",
    "tracks_clean.write.mode(\"overwrite\").parquet(data_path + \"tracks_clean.parquet\")\n",
    "print(\"Archivo Parquet guardado en /home/jovyan/work/data/spotify/tracks_clean.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a4ef6-b34b-4e12-8cd9-c3b9078e7020",
   "metadata": {},
   "source": [
    "# Paso 6: Estadísticas descriptivas de las características de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb52c9e-e02f-44fd-b367-eeff2b9421a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas descriptivas de características de audio:\n",
      "+-------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-------------------+------------------+\n",
      "|summary|       danceability|             energy|          loudness|        speechiness|       acousticness|   instrumentalness|          liveness|            valence|             tempo|\n",
      "+-------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-------------------+------------------+\n",
      "|  count|             581260|             581260|            581260|             581260|             581260|             581260|            581260|             581260|            581260|\n",
      "|   mean| 0.5647308442005304|  0.543682586482467|-10.16973024980216|0.10513623077452135|0.44778156191989277|0.11338287403979273|0.2138189175584078|  0.553689442912121|118.54083997178523|\n",
      "| stddev|0.16548384094052934|0.25129853986883316| 5.065166009199545|0.18041739829036987|0.34826590391864226|0.26686996855984996|0.1842531239288979|0.25709399356386686| 29.74808469913343|\n",
      "|    min|                0.0|                0.0|            -0.004|                0.0|                0.0|                0.0|               0.0|                0.0|               0.0|\n",
      "|    max|              0.991|            9.9e-05|             5.376|              0.971|              9e-06|              9e-06|               1.0|           6.41e-05|            99.999|\n",
      "+-------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar columnas de características de audio para análisis\n",
    "audio_cols = [\"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "              \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]\n",
    "\n",
    "print(\"Estadísticas descriptivas de características de audio:\")\n",
    "tracks_clean.select(audio_cols).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49911d6e-cc9a-4a9f-ab5f-4333cd91b61e",
   "metadata": {},
   "source": [
    "# Paso 7: Agregados por década"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c840edcb-9e2a-41c6-bf52-646487cb7bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+----------------+----------+------------+---------------+----------------+--------------------+------------+-----------+---------+\n",
      "|decade|tracks_count|avg_danceability|avg_energy|avg_loudness|avg_speechiness|avg_acousticness|avg_instrumentalness|avg_liveness|avg_valence|avg_tempo|\n",
      "+------+------------+----------------+----------+------------+---------------+----------------+--------------------+------------+-----------+---------+\n",
      "|1920  |7601        |0.604           |0.281     |-14.8       |0.292          |0.89            |0.326               |0.205       |0.6        |113.1    |\n",
      "|1930  |12952       |0.552           |0.307     |-13.5       |0.195          |0.869           |0.275               |0.217       |0.573      |112.8    |\n",
      "|1940  |17772       |0.477           |0.269     |-14.2       |0.1            |0.915           |0.382               |0.214       |0.504      |107.1    |\n",
      "|1950  |33748       |0.488           |0.303     |-14.3       |0.108          |0.837           |0.25                |0.211       |0.506      |111.1    |\n",
      "|1960  |45956       |0.499           |0.407     |-12.5       |0.077          |0.681           |0.162               |0.213       |0.565      |114.2    |\n",
      "|1970  |61045       |0.524           |0.502     |-11.4       |0.104          |0.501           |0.101               |0.222       |0.581      |117.4    |\n",
      "|1980  |81815       |0.564           |0.55      |-11.3       |0.139          |0.406           |0.081               |0.226       |0.581      |118.9    |\n",
      "|1990  |108607      |0.572           |0.575     |-10.3       |0.099          |0.366           |0.073               |0.217       |0.57       |119.7    |\n",
      "|2000  |86622       |0.59            |0.649     |-7.6        |0.08           |0.313           |0.056               |0.211       |0.564      |121.4    |\n",
      "|2010  |104965      |0.608           |0.658     |-7.3        |0.091          |0.288           |0.089               |0.206       |0.514      |122.1    |\n",
      "|2020  |20177       |0.662           |0.633     |-7.6        |0.118          |0.274           |0.115               |0.187       |0.503      |121.9    |\n",
      "+------+------------+----------------+----------+------------+---------------+----------------+--------------------+------------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear columna 'decade' que agrupa el año de lanzamiento por década (ejemplo: 1995 -> 1990)\n",
    "tracks_clean = tracks_clean.withColumn(\"decade\", (F.floor(F.col(\"release_year\")/10) * 10).cast(\"int\"))\n",
    "\n",
    "# Agrupar por década y calcular el número de canciones y promedio de características de audio por década\n",
    "tracks_clean.groupBy(\"decade\").agg(\n",
    "    F.count(\"*\").alias(\"tracks_count\"),\n",
    "    F.round(F.avg(\"danceability\"), 3).alias(\"avg_danceability\"),\n",
    "    F.round(F.avg(\"energy\"), 3).alias(\"avg_energy\"),\n",
    "    F.round(F.avg(\"loudness\"), 1).alias(\"avg_loudness\"),\n",
    "    F.round(F.avg(\"speechiness\"), 3).alias(\"avg_speechiness\"),\n",
    "    F.round(F.avg(\"acousticness\"), 3).alias(\"avg_acousticness\"),\n",
    "    F.round(F.avg(\"instrumentalness\"), 3).alias(\"avg_instrumentalness\"),\n",
    "    F.round(F.avg(\"liveness\"), 3).alias(\"avg_liveness\"),\n",
    "    F.round(F.avg(\"valence\"), 3).alias(\"avg_valence\"),\n",
    "    F.round(F.avg(\"tempo\"), 1).alias(\"avg_tempo\")\n",
    ").orderBy(\"decade\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350ac09-cf39-4960-b5bf-23d749c069b1",
   "metadata": {},
   "source": [
    "# Bloque 8: Visualización de Distribuciones y Mapa de Calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add9b81-b4b5-490d-a79f-36863b267b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Iniciar medición de tiempo\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir las columnas de características de audio\n",
    "audio_cols = [\"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "              \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]\n",
    "\n",
    "# Asegurarse de que cada columna de audio esté en tipo double\n",
    "for col_name in audio_cols:\n",
    "    tracks_clean = tracks_clean.withColumn(col_name, F.col(col_name).cast(\"double\"))\n",
    "\n",
    "# Extraer una muestra pequeña para visualización (1% de los datos)\n",
    "sample_df = tracks_clean.select(audio_cols).sample(fraction=0.01, seed=42).toPandas()\n",
    "\n",
    "# Generar histogramas para cada característica de audio\n",
    "for col_name in audio_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(sample_df[col_name], bins=30, kde=True)\n",
    "    plt.title(f\"Distribución de {col_name}\")\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n",
    "\n",
    "# Calcular la matriz de correlación usando Spark\n",
    "corr_matrix = []\n",
    "for col1 in audio_cols:\n",
    "    row = []\n",
    "    for col2 in audio_cols:\n",
    "        corr_val = tracks_clean.stat.corr(col1, col2)\n",
    "        row.append(corr_val)\n",
    "    corr_matrix.append(row)\n",
    "\n",
    "# Convertir la matriz de correlación a un DataFrame de pandas para graficar el mapa de calor\n",
    "corr_df = pd.DataFrame(corr_matrix, index=audio_cols, columns=audio_cols)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_df, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Mapa de calor de correlaciones de características de audio\")\n",
    "plt.show()\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "elapsed_time = int(time.time() - start_time)\n",
    "print(\"Proceso completado se tardó alrededor de %d segundos\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332bfc5-b575-4bfc-99ac-d680ceb0c709",
   "metadata": {},
   "source": [
    "# Bloque 9: Análisis de Popularidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca5b44-6444-41c6-b582-1dac4f14fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Convertir la columna 'popularity' a entero (si no lo está)\n",
    "tracks_clean = tracks_clean.withColumn(\"popularity\", F.col(\"popularity\").cast(\"int\"))\n",
    "\n",
    "# Crear una nueva columna de categoría de popularidad\n",
    "tracks_clean = tracks_clean.withColumn(\"popularity_category\", \n",
    "    F.when(F.col(\"popularity\") >= 70, \"Alta\")\n",
    "     .when((F.col(\"popularity\") >= 50) & (F.col(\"popularity\") < 70), \"Media\")\n",
    "     .when((F.col(\"popularity\") >= 30) & (F.col(\"popularity\") < 50), \"Baja\")\n",
    "     .otherwise(\"Muy baja\")\n",
    ")\n",
    "\n",
    "# Mostrar el conteo de canciones por categoría\n",
    "tracks_clean.groupBy(\"popularity_category\").count().orderBy(\"popularity_category\").show()\n",
    "\n",
    "# Calcular estadísticas descriptivas de audio por categoría de popularidad\n",
    "pop_stats = tracks_clean.groupBy(\"popularity_category\").agg(\n",
    "    F.round(F.avg(\"danceability\"), 3).alias(\"avg_danceability\"),\n",
    "    F.round(F.avg(\"energy\"), 3).alias(\"avg_energy\"),\n",
    "    F.round(F.avg(\"acousticness\"), 3).alias(\"avg_acousticness\"),\n",
    "    F.round(F.avg(\"instrumentalness\"), 3).alias(\"avg_instrumentalness\"),\n",
    "    F.round(F.avg(\"liveness\"), 3).alias(\"avg_liveness\"),\n",
    "    F.round(F.avg(\"valence\"), 3).alias(\"avg_valence\"),\n",
    "    F.round(F.avg(\"tempo\"), 1).alias(\"avg_tempo\")\n",
    ").orderBy(\"popularity_category\")\n",
    "pop_stats.show()\n",
    "\n",
    "# Para visualizar, extraemos una muestra pequeña (1% de los datos) y la convertimos a Pandas\n",
    "pop_sample = tracks_clean.select(\"popularity_category\", *audio_cols).sample(0.01, seed=42).toPandas()\n",
    "\n",
    "for col_name in audio_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=\"popularity_category\", y=col_name, data=pop_sample,\n",
    "                order=[\"Muy baja\", \"Baja\", \"Media\", \"Alta\"])\n",
    "    plt.title(f\"{col_name} por categoría de popularidad\")\n",
    "    plt.xlabel(\"Categoría de Popularidad\")\n",
    "    plt.ylabel(col_name)\n",
    "    plt.show()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Proceso de análisis de popularidad completado en %d segundos\" % int(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337dc7d9-17cc-4b33-ab5d-0e5549b77adc",
   "metadata": {},
   "source": [
    "# Bloque 10: Reto Final – Clustering y Motor de Recomendación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990b889-f32c-4caf-b258-1b7399a35aa0",
   "metadata": {},
   "source": [
    "### Una función para filtrar (eliminar) outliers en columnas específicas (“speechiness”, “loudness”, “instrumentalness” y “liveness”) usando percentiles (por ejemplo, 5% y 95%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b1b7c-5c95-47ba-9a7f-f6fbdb1ba958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql.types import DoubleType\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Iniciar la medición del tiempo\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir las características de audio para el clustering\n",
    "features = [\"danceability\", \"energy\", \"loudness\", \"speechiness\", \n",
    "            \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]\n",
    "\n",
    "# Asegurarse de que cada columna esté en tipo double\n",
    "for col_name in features:\n",
    "    tracks_clean = tracks_clean.withColumn(col_name, F.col(col_name).cast(\"double\"))\n",
    "\n",
    "# Función para filtrar outliers usando percentiles\n",
    "def filter_outliers(df, col_name, lower_quantile=0.05, upper_quantile=0.95):\n",
    "    q = df.approxQuantile(col_name, [lower_quantile, upper_quantile], 0.0)\n",
    "    return df.filter((F.col(col_name) >= q[0]) & (F.col(col_name) <= q[1]))\n",
    "\n",
    "# Aplicar filtrado de outliers a columnas específicas\n",
    "for col_name in [\"speechiness\", \"loudness\", \"instrumentalness\", \"liveness\"]:\n",
    "    tracks_clean = filter_outliers(tracks_clean, col_name, 0.05, 0.95)\n",
    "\n",
    "# (Opcional) Visualización de histogramas para verificar la distribución (puedes comentar si ya lo hiciste)\n",
    "sample_df = tracks_clean.select(features).sample(fraction=0.01, seed=42).toPandas()\n",
    "for col_name in features:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(sample_df[col_name], bins=30, kde=True)\n",
    "    plt.title(f\"Distribución de {col_name}\")\n",
    "    plt.xlabel(col_name)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n",
    "\n",
    "# Ensamblar las características en un vector\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "\n",
    "# Definir el modelo de K-Means (ajusta k según tus necesidades; aquí k=5 y seed para reproducibilidad)\n",
    "kmeans = KMeans(featuresCol=\"scaledFeatures\", predictionCol=\"cluster\", k=5, seed=42)\n",
    "\n",
    "# Crear la pipeline de transformación y clustering\n",
    "pipeline = Pipeline(stages=[assembler, scaler, kmeans])\n",
    "model = pipeline.fit(tracks_clean)\n",
    "tracks_clustered = model.transform(tracks_clean)\n",
    "\n",
    "# Evaluar la calidad del clustering usando el Silhouette Score\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"scaledFeatures\", predictionCol=\"cluster\")\n",
    "silhouette = evaluator.evaluate(tracks_clustered)\n",
    "print(f\"Silhouette Score del clustering: {silhouette:.3f}\")\n",
    "\n",
    "# Convertir los centros a listas simples y difundirlos (broadcast)\n",
    "# <<--- Corrección: llamar al método clusterCenters() y transformar cada centro a lista\n",
    "centers = model.stages[-1].clusterCenters()  \n",
    "centers_list = [list(center) for center in centers]\n",
    "bc_centers = spark.sparkContext.broadcast(centers_list)\n",
    "\n",
    "# Función para calcular la distancia euclidiana al centro del cluster\n",
    "def compute_distance(features, cluster):\n",
    "    center = bc_centers.value[int(cluster)]\n",
    "    return float(np.linalg.norm(np.array(features) - np.array(center)))\n",
    "\n",
    "# Crear un UDF para calcular la distancia\n",
    "distance_udf = F.udf(compute_distance, DoubleType())\n",
    "\n",
    "# Calcular la distancia de cada punto a su centro de cluster\n",
    "tracks_with_distance = tracks_clustered.withColumn(\"distance\", distance_udf(F.col(\"scaledFeatures\"), F.col(\"cluster\")))\n",
    "\n",
    "# Calcular la diversidad promedio por cluster (distancia promedio)\n",
    "diversity_df = tracks_with_distance.groupBy(\"cluster\").agg(F.round(F.avg(\"distance\"), 3).alias(\"avg_distance\"))\n",
    "diversity_metrics = {row[\"cluster\"]: row[\"avg_distance\"] for row in diversity_df.collect()}\n",
    "\n",
    "print(\"Diversidad promedio por cluster:\")\n",
    "for cluster, diversity in sorted(diversity_metrics.items()):\n",
    "    print(f\"  Cluster {cluster}: {diversity}\")\n",
    "\n",
    "# Mostrar algunos ejemplos de asignación de cluster\n",
    "tracks_clustered.select(\"id\", \"name\", \"release_year\", \"popularity\", \"cluster\").show(10, truncate=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Proceso de clustering completado en {int(end_time - start_time)} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0ef24-0840-4c4d-8145-85eecb29c182",
   "metadata": {},
   "source": [
    "# Bloque 11: Interfaz Interactiva con ipywidgets para Explorar Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083fb7c-219a-4c4d-ab8d-89d4a6a517d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def show_recommendations(cluster_number):\n",
    "    # Extraer 10 registros del cluster seleccionado y convertirlos a pandas para visualización\n",
    "    cluster_df = tracks_clustered.filter(F.col(\"cluster\") == cluster_number).limit(10).toPandas()\n",
    "    print(f\"Ejemplos del Cluster {cluster_number}:\")\n",
    "    display(cluster_df[['id', 'name', 'release_year', 'popularity', 'cluster']])\n",
    "\n",
    "# Crear un slider para seleccionar el cluster (0 a 4, porque k=5)\n",
    "cluster_selector = widgets.IntSlider(\n",
    "    value=0, min=0, max=4, step=1, description=\"Cluster:\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Crear un output widget para mostrar la tabla\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "def on_cluster_change(change):\n",
    "    if change['name'] == 'value':\n",
    "        output_widget.clear_output()\n",
    "        with output_widget:\n",
    "            show_recommendations(change['new'])\n",
    "\n",
    "cluster_selector.observe(on_cluster_change)\n",
    "\n",
    "print(\"Seleccione el número de cluster para ver recomendaciones:\")\n",
    "display(cluster_selector, output_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be87889-9fc7-4674-92b6-164e81624150",
   "metadata": {},
   "source": [
    "# Bloque 12: Interfaz Conceptual y Propuesta de Escalabilidad "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b96ebd-6b27-4528-9990-32d677d38d27",
   "metadata": {},
   "source": [
    "# Evaluación del Sistema de Recomendación y Propuesta de Escalabilidad\n",
    "\n",
    "## Evaluación del Sistema de Recomendación\n",
    "\n",
    "Para evaluar nuestro motor de recomendación, consideramos las siguientes métricas:\n",
    "- **Diversidad de Recomendaciones:**  \n",
    "  Mide la variedad en las canciones recomendadas. Se puede calcular como la distancia promedio en el espacio de características entre las canciones en una lista de recomendaciones.  \n",
    "  *Ejemplo:* Calcular la distancia euclidiana promedio entre los vectores de características de las canciones recomendadas.\n",
    "  \n",
    "- **Novedad (Serendipity):**  \n",
    "  Mide cuán inesperadas son las recomendaciones para el usuario, es decir, la capacidad del sistema para sugerir canciones que no se basen únicamente en sus preferencias previas pero que sean sorprendentemente atractivas.  \n",
    "  *Conceptualmente:* Una recomendación es serendípica si el usuario no esperaba esa sugerencia y, sin embargo, le resulta interesante.\n",
    "\n",
    "- **Precisión:**  \n",
    "  En un sistema supervisado, la precisión se calcula como la fracción de recomendaciones relevantes entre el total recomendado.  \n",
    "  *En nuestro caso:* Si contamos con algún set de validación (por ejemplo, basado en reproducciones o likes), se podría calcular la precisión de las recomendaciones.\n",
    "\n",
    "## Interfaz Conceptual para el Motor de Recomendación\n",
    "\n",
    "El sistema de recomendación se compone de las siguientes secciones:\n",
    "- **Para ti:** Recomendaciones personalizadas basadas en el perfil y el historial del usuario.\n",
    "- **Novedades:** Canciones recientes (estrenos) que podrían interesar.\n",
    "- **Clásicos:** Canciones atemporales y populares.\n",
    "- **Por Género:** Recomendaciones segmentadas por géneros musicales.\n",
    "\n",
    "La interfaz podría implementarse en un dashboard web utilizando herramientas como **Dash** o **Streamlit** para una experiencia interactiva. En un entorno de prototipado (por ejemplo, Jupyter Notebook) se puede simular la interfaz usando **ipywidgets** (como se muestra en el Bloque 11).\n",
    "\n",
    "## Propuesta de Escalabilidad\n",
    "\n",
    "Para escalar la solución a millones de usuarios y canciones, se propone la siguiente arquitectura:\n",
    "1. **Ingesta de Datos en Tiempo Real:**  \n",
    "   - **Apache Kafka:** Para la ingesta continua de eventos (reproducciones, preferencias, interacciones).\n",
    "   \n",
    "2. **Procesamiento Distribuido:**  \n",
    "   - **Apache Spark en clúster (Kubernetes o YARN):** Para procesamiento batch y en tiempo real. Spark se encarga de la transformación de datos, clustering, entrenamiento de modelos de ML y generación de recomendaciones.\n",
    "   \n",
    "3. **Almacenamiento:**  \n",
    "   - **Cassandra o HDFS:** Para almacenar grandes volúmenes de datos históricos, perfiles de usuario y resultados de procesamiento.\n",
    "   \n",
    "4. **Motor de Recomendación:**  \n",
    "   - Implementado combinando análisis de contenido (clustering basado en características de audio) con modelos colaborativos (filtrado colaborativo). Se puede utilizar Spark ML para entrenar modelos de clasificación o regresión.\n",
    "   \n",
    "5. **Interfaz y API:**  \n",
    "   - **REST API:** Para servir las recomendaciones en tiempo real.  \n",
    "   - **Dashboard Interactivo:** Para visualización y ajuste de parámetros, utilizando herramientas modernas de visualización web.\n",
    "\n",
    "Esta arquitectura garantiza que la solución pueda manejar altos volúmenes de datos, actualizaciones en tiempo real y escalar horizontalmente en un entorno distribuido.\n",
    "\n",
    "---\n",
    "\n",
    "*Fin de la propuesta conceptual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbaecf-b973-42e9-9e31-9edefb76570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que en el bloque 10 creaste 'tracks_clustered'\n",
    "# Al final de ese bloque, agregas:\n",
    "\n",
    "tracks_clustered.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"/home/jovyan/work/data/spotify/tracks_clustered.parquet\")\n",
    "print(\"parquet saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6498a-984d-4459-815d-795f1bd8651c",
   "metadata": {},
   "source": [
    "# Bloque 13 Ejemplo de Cálculo de Métricas de Diversidad (Conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e486e7-2fc4-43ed-ab5b-6f353355f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# BLOCK 13: Compute diversity for each cluster\n",
    "# ----------------------------------------------------------------\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def compute_diversity_spark(cluster_df):\n",
    "    \"\"\"\n",
    "    cluster_df is a Spark DataFrame with a 'scaledFeatures' column of type Vector.\n",
    "    We'll collect the scaled features to Python, then compute pairwise distances.\n",
    "    \"\"\"\n",
    "    # Collect scaledFeatures to a list of numpy arrays\n",
    "    rows = cluster_df.select(\"scaledFeatures\").collect()\n",
    "    if len(rows) < 2:\n",
    "        return 0.0\n",
    "    # Convert each row's scaledFeatures to numpy\n",
    "    arr = np.array([np.array(r[\"scaledFeatures\"]) for r in rows])\n",
    "    # Compute average distance\n",
    "    dist_avg = pdist(arr, metric='euclidean').mean()\n",
    "    return float(dist_avg)\n",
    "\n",
    "for cluster_num in range(5):\n",
    "    cluster_df = tracks_clustered.filter(F.col(\"cluster\") == cluster_num)\n",
    "    diversity_value = compute_diversity_spark(cluster_df)\n",
    "    print(f\"Diversidad promedio del Cluster {cluster_num}: {diversity_value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0e8dc-fc4a-4a61-a008-6e6d3d3d2543",
   "metadata": {},
   "source": [
    "### Aquí se está calculando la diversidad de cada cluster, que se mide como la distancia promedio (por ejemplo, euclidiana) entre los vectores de características de las canciones dentro de ese cluster.\n",
    "Interpretación:\n",
    "\n",
    "    \t•\tDiversidad alta: Un valor mayor indica que las canciones dentro del cluster son más variadas etre sí en términos de características de audio.\n",
    " \n",
    "      •\tDiversidad baja: Un valor menor sugiere que las canciones son más similares entre sí.\n",
    "\n",
    "En este caso, el Cluster 0 tiene la diversidad más alta (3.700), lo que indica una mayor variación interna, mientras que el Cluster 2 tiene la menor diversidad (3.054), implicando que las canciones en ese grupo son bastante homogéneas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c8e6f-8205-437c-a0b2-b699e61f7966",
   "metadata": {},
   "source": [
    "# Dashboard Interactivo con JupyterDash para Recomendaciones Musicales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486af058-0616-4749-9016-8cc2064e0cbb",
   "metadata": {},
   "source": [
    "# Bloque 14: Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af2399-3d96-4997-95d4-e38a1fe1d516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
